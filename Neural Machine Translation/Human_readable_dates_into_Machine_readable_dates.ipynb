{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human readable dates into Machine readable dates.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A Neural Machine Translation (NMT) model to translate human-readable dates (\"25th of June, 2009\") into machine-readable dates (\"2009-06-25\").\n",
        "\n",
        "An attention model, one of the most sophisticated sequence-to-sequence models will be build to carry out the task"
      ],
      "metadata": {
        "id": "5wOKsTY-XgrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Packages"
      ],
      "metadata": {
        "id": "AOJyYpBKbF5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "EPVpSeEhXWYL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "from nmt_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "We will train the model on a dataset of 10,000 human readable dates and their equivalent, standardized, machine readable dates."
      ],
      "metadata": {
        "id": "NrOUpFS5c4bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 10000\n",
        "# dataset: a list of tuples of (human readable date, machine readable date).\n",
        "# human_vocab: a python dictionary mapping all characters used in the human readable dates to an integer-valued index.\n",
        "# machine_vocab: a python dictionary mapping all characters used in machine readable dates to an integer-valued index.\n",
        "# Note: These indices are not necessarily consistent with human_vocab.\n",
        "# inv_machine_vocab: the inverse dictionary of machine_vocab, mapping from indices back to characters.\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGkr2YFYP3k",
        "outputId": "b58c40e8-97d7-47ef-a549-f426d209697e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 17937.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UyMfAmiYaJy",
        "outputId": "f4752621-f8e9-47d3-bfa1-7e6525307d61"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('28 oct 1990', '1990-10-28'),\n",
              " ('1 may 1998', '1998-05-01'),\n",
              " ('wednesday april 2 2003', '2003-04-02'),\n",
              " ('29.04.99', '1999-04-29'),\n",
              " ('august 27 2008', '2008-08-27'),\n",
              " ('october 11 1991', '1991-10-11'),\n",
              " ('16 apr 1987', '1987-04-16'),\n",
              " ('march 26 2021', '2021-03-26'),\n",
              " ('monday july 18 1977', '1977-07-18'),\n",
              " ('tuesday january 24 2012', '2012-01-24')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ISPaL_dxQ5",
        "outputId": "1ede5536-8831-4d09-ab0d-5d6a52ee9b98"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '.': 1,\n",
              " '/': 2,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '5': 8,\n",
              " '6': 9,\n",
              " '7': 10,\n",
              " '8': 11,\n",
              " '9': 12,\n",
              " '<pad>': 36,\n",
              " '<unk>': 35,\n",
              " 'a': 13,\n",
              " 'b': 14,\n",
              " 'c': 15,\n",
              " 'd': 16,\n",
              " 'e': 17,\n",
              " 'f': 18,\n",
              " 'g': 19,\n",
              " 'h': 20,\n",
              " 'i': 21,\n",
              " 'j': 22,\n",
              " 'l': 23,\n",
              " 'm': 24,\n",
              " 'n': 25,\n",
              " 'o': 26,\n",
              " 'p': 27,\n",
              " 'r': 28,\n",
              " 's': 29,\n",
              " 't': 30,\n",
              " 'u': 31,\n",
              " 'v': 32,\n",
              " 'w': 33,\n",
              " 'y': 34}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdpvMZOSd_z5",
        "outputId": "c36a7a05-cd47-4dab-ca12-47113dee592d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tx = 30 # maximum lenght of the human readable data\n",
        "Ty = 10 # length of the output string,\"YYYY-MM-DD\" is 10 characters long.\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzadYx1Eff2w",
        "outputId": "d00763c1-2714-49a9-fd3b-fa9f7109f505"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print()\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print()\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1NvDjgefvud",
        "outputId": "89d89477-3724-48e1-f769-e63df43c9e6e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source date: 28 oct 1990\n",
            "Target date: 1990-10-28\n",
            "\n",
            "Source after preprocessing (indices): [ 5 11  0 26 15 30  0  4 12 12  3 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [ 2 10 10  1  0  2  1  0  3  9]\n",
            "\n",
            "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview of the attention model\n",
        "\n",
        "![](https://raw.githubusercontent.com/amanchadha/coursera-deep-learning-specialization/3a623a00267716d1695e0ce57480f9027648ad4e/C5%20-%20Sequence%20Models/Week%203/Machine%20Translation/images/attn_mechanism.png)\n",
        "![](https://raw.githubusercontent.com/amanchadha/coursera-deep-learning-specialization/3a623a00267716d1695e0ce57480f9027648ad4e/C5%20-%20Sequence%20Models/Week%203/Machine%20Translation/images/attn_model.png)"
      ],
      "metadata": {
        "id": "SXYds8yn022x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined shared layers as global variables\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)"
      ],
      "metadata": {
        "id": "4O_6_MRTg7a5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "    \"\"\"\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "    \n",
        "    Arguments:\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "    \n",
        "    Returns:\n",
        "    context -- context vector, input of the next (post-attention) LSTM cell\n",
        "    \"\"\"\n",
        "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" \n",
        "    s_prev = repeator(s_prev)\n",
        "    # Use concatenator to concatenate a and s_prev on the last axis\n",
        "    concat = concatenator([a,s_prev])\n",
        "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e\n",
        "    e = densor1(concat)\n",
        "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies.\n",
        "    energies = densor2(e)\n",
        "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" \n",
        "    alphas = activator(energies)\n",
        "    # Use dotor together with \"alphas\" and \"a\", in this order, to compute the context vector to be given to the next (post-attention) LSTM-cell\n",
        "    context = dotor([alphas,a])\n",
        "    \n",
        "    return context"
      ],
      "metadata": {
        "id": "8F4Jyed4j5AD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
        "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
        "\n",
        "# this is the post attention LSTM cell.  \n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True) \n",
        "output_layer = Dense(len(machine_vocab), activation=softmax)"
      ],
      "metadata": {
        "id": "-FVkxlCT0VxA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "XTAMhlNK3Leo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_a -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
        "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the inputs of the model with a shape (Tx,)\n",
        "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
        "    # for the decoder LSTM with shape (n_s,)\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = []\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X) # pre-attention Bi-LSTM\n",
        "    \n",
        "    for t in range(Ty):\n",
        "        context = one_step_attention(a, s)\n",
        "\n",
        "        s, _, c = post_activation_LSTM_cell(context,initial_state=[s, c])\n",
        "        \n",
        "        out = output_layer(s)\n",
        "        \n",
        "        outputs.append(out)\n",
        "    model = Model(inputs=[X, s0, c0],outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "n2mb0vyN2Jux"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab)) # create the model"
      ],
      "metadata": {
        "id": "t6OHWFpR4VCX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYu9hZt94dXq",
        "outputId": "84b18171-f855-4f72-fae3-0c891ee2b4ae"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 30, 37)]     0           []                               \n",
            "                                                                                                  \n",
            " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 30, 64)      17920       ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " repeat_vector_1 (RepeatVector)  (None, 30, 64)      0           ['s0[0][0]',                     \n",
            "                                                                  'lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[8][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 30, 128)      0           ['bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[0][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[1][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[2][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[3][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[4][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[5][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[6][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[7][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[8][0]',        \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'repeat_vector_1[9][0]']        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 30, 10)       1290        ['concatenate_1[0][0]',          \n",
            "                                                                  'concatenate_1[1][0]',          \n",
            "                                                                  'concatenate_1[2][0]',          \n",
            "                                                                  'concatenate_1[3][0]',          \n",
            "                                                                  'concatenate_1[4][0]',          \n",
            "                                                                  'concatenate_1[5][0]',          \n",
            "                                                                  'concatenate_1[6][0]',          \n",
            "                                                                  'concatenate_1[7][0]',          \n",
            "                                                                  'concatenate_1[8][0]',          \n",
            "                                                                  'concatenate_1[9][0]']          \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 30, 1)        11          ['dense_3[0][0]',                \n",
            "                                                                  'dense_3[1][0]',                \n",
            "                                                                  'dense_3[2][0]',                \n",
            "                                                                  'dense_3[3][0]',                \n",
            "                                                                  'dense_3[4][0]',                \n",
            "                                                                  'dense_3[5][0]',                \n",
            "                                                                  'dense_3[6][0]',                \n",
            "                                                                  'dense_3[7][0]',                \n",
            "                                                                  'dense_3[8][0]',                \n",
            "                                                                  'dense_3[9][0]']                \n",
            "                                                                                                  \n",
            " attention_weights (Activation)  (None, 30, 1)       0           ['dense_4[0][0]',                \n",
            "                                                                  'dense_4[1][0]',                \n",
            "                                                                  'dense_4[2][0]',                \n",
            "                                                                  'dense_4[3][0]',                \n",
            "                                                                  'dense_4[4][0]',                \n",
            "                                                                  'dense_4[5][0]',                \n",
            "                                                                  'dense_4[6][0]',                \n",
            "                                                                  'dense_4[7][0]',                \n",
            "                                                                  'dense_4[8][0]',                \n",
            "                                                                  'dense_4[9][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 1, 64)        0           ['attention_weights[0][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[1][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[2][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[3][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[4][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[5][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[6][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[7][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[8][0]',      \n",
            "                                                                  'bidirectional_2[0][0]',        \n",
            "                                                                  'attention_weights[9][0]',      \n",
            "                                                                  'bidirectional_2[0][0]']        \n",
            "                                                                                                  \n",
            " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 64),         33024       ['dot_1[0][0]',                  \n",
            "                                 (None, 64),                      's0[0][0]',                     \n",
            "                                 (None, 64)]                      'c0[0][0]',                     \n",
            "                                                                  'dot_1[1][0]',                  \n",
            "                                                                  'lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[0][2]',                 \n",
            "                                                                  'dot_1[2][0]',                  \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[1][2]',                 \n",
            "                                                                  'dot_1[3][0]',                  \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[2][2]',                 \n",
            "                                                                  'dot_1[4][0]',                  \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[3][2]',                 \n",
            "                                                                  'dot_1[5][0]',                  \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[4][2]',                 \n",
            "                                                                  'dot_1[6][0]',                  \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[5][2]',                 \n",
            "                                                                  'dot_1[7][0]',                  \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[6][2]',                 \n",
            "                                                                  'dot_1[8][0]',                  \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[7][2]',                 \n",
            "                                                                  'dot_1[9][0]',                  \n",
            "                                                                  'lstm_3[8][0]',                 \n",
            "                                                                  'lstm_3[8][2]']                 \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 11)           715         ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[1][0]',                 \n",
            "                                                                  'lstm_3[2][0]',                 \n",
            "                                                                  'lstm_3[3][0]',                 \n",
            "                                                                  'lstm_3[4][0]',                 \n",
            "                                                                  'lstm_3[5][0]',                 \n",
            "                                                                  'lstm_3[6][0]',                 \n",
            "                                                                  'lstm_3[7][0]',                 \n",
            "                                                                  'lstm_3[8][0]',                 \n",
            "                                                                  'lstm_3[9][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compilation\n",
        "opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oqbp7s7j4q4-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "metadata": {
        "id": "1VpFnUOV5iil"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRmL6dHI6hFf",
        "outputId": "62b90566-5925-4a1f-b062-9524e74d3f34"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 28s 80ms/step - loss: 17.4401 - dense_5_loss: 1.2771 - dense_5_1_loss: 1.1232 - dense_5_2_loss: 1.8888 - dense_5_3_loss: 2.6730 - dense_5_4_loss: 0.7981 - dense_5_5_loss: 1.4124 - dense_5_6_loss: 2.8489 - dense_5_7_loss: 1.0304 - dense_5_8_loss: 1.7926 - dense_5_9_loss: 2.5956 - dense_5_accuracy: 0.4756 - dense_5_1_accuracy: 0.6488 - dense_5_2_accuracy: 0.2692 - dense_5_3_accuracy: 0.0785 - dense_5_4_accuracy: 0.9891 - dense_5_5_accuracy: 0.2707 - dense_5_6_accuracy: 0.0276 - dense_5_7_accuracy: 0.9604 - dense_5_8_accuracy: 0.2175 - dense_5_9_accuracy: 0.0919\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99efb45f10>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/models/model.h5') # model was trained longer ,so load the model with trained weights"
      ],
      "metadata": {
        "id": "uTHrdxTC6kDF"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction new data"
      ],
      "metadata": {
        "id": "G19VLWah_HWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "s00 = np.zeros((1, n_s))\n",
        "c00 = np.zeros((1, n_s))\n",
        "for example in EXAMPLES:\n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    #print(source)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    source = np.swapaxes(source, 0, 1)\n",
        "    source = np.expand_dims(source, axis=0)\n",
        "    prediction = model.predict([source, s00, c00])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX4V5Rgt7Sf4",
        "outputId": "36a11b7b-71a4-4bd0-bd3d-84a4c2150914"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: 3 May 1979\n",
            "output: 1979-05-33 \n",
            "\n",
            "source: 5 April 09\n",
            "output: 2009-04-05 \n",
            "\n",
            "source: 21th of August 2016\n",
            "output: 2016-08-20 \n",
            "\n",
            "source: Tue 10 Jul 2007\n",
            "output: 2007-07-10 \n",
            "\n",
            "source: Saturday May 9 2018\n",
            "output: 2018-05-09 \n",
            "\n",
            "source: March 3 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "source: March 3rd 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "source: 1 March 2001\n",
            "output: 2001-03-01 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_date(sentence):\n",
        "    source = string_to_int(sentence, Tx, human_vocab)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    source = np.swapaxes(source, 0, 1)\n",
        "    source = np.expand_dims(source, axis=0)\n",
        "    prediction = model.predict([source, s00, c00])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    print(\"source:\", sentence)\n",
        "    print(\"output:\", ''.join(output),\"\\n\")\n",
        "example = \"4th of july 2001\"\n",
        "translate_date(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMlvysa7gz0",
        "outputId": "8cfe790c-09f7-4720-b029-946148655bdd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: 4th of july 2001\n",
            "output: 2001-07-04 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xjj25aja_phD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}